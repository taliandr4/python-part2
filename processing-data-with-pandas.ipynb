{"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Processing data with pandas\n\nFinnish university students are encouraged to use the CSC Notebooks platform.<br/>\n<a href=\"https://notebooks.csc.fi/\"><img alt=\"CSC badge\" src=\"https://img.shields.io/badge/launch-CSC%20notebook-blue.svg\" style=\"vertical-align:text-bottom\"></a>\n\nOthers can follow the lesson and fill in their student notebooks using Binder.<br/>\n<a href=\"https://mybinder.org/v2/gh/geo-python/notebooks/master?urlpath=lab/tree/L5/processing-data-with-pandas.ipynb\"><img alt=\"Binder badge\" src=\"https://img.shields.io/badge/launch-binder-red.svg\" style=\"vertical-align:text-bottom\"></a>\n\nDuring the first part of this lesson you learned the basics of pandas data structures (*Series* and *DataFrame*) and got familiar with basic methods loading and exploring data.\nHere, we will continue with basic data manipulation and analysis methods such calculations and selections.\n\nWe are now working in a new notebook file and we need to import pandas again. ","metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true,"tags":[]},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Let's work with the same input data `'Kumpula-June-2016-w-metadata.txt'` and load it using the `pd.read_csv()` method. Remember, that the first 8 lines contain metadata so we can skip those. This time, let's store the filepath into a separate variable in order to make the code more readable and easier to change afterwards: ","metadata":{}},{"cell_type":"code","source":"# Define file path:\nfp = \"Kumpula-June-2016-w-metadata.txt\"\n\n# Read in the data from the file (starting at row 9):\ndata = pd.read_csv(fp, skiprows=8)","metadata":{"tags":[],"collapsed":false,"jupyter":{"outputs_hidden":false},"deletable":true,"editable":true,"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Remember to always check the data after reading it in:","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"tags":[]},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   YEARMODA  TEMP   MAX   MIN\n0  20160601  65.5  73.6  54.7\n1  20160602  65.8  80.8  55.0\n2  20160603  68.4   NaN  55.6\n3  20160604  57.5  70.9  47.3\n4  20160605  51.4  58.3  43.2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>YEARMODA</th>\n      <th>TEMP</th>\n      <th>MAX</th>\n      <th>MIN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20160601</td>\n      <td>65.5</td>\n      <td>73.6</td>\n      <td>54.7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20160602</td>\n      <td>65.8</td>\n      <td>80.8</td>\n      <td>55.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20160603</td>\n      <td>68.4</td>\n      <td>NaN</td>\n      <td>55.6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20160604</td>\n      <td>57.5</td>\n      <td>70.9</td>\n      <td>47.3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20160605</td>\n      <td>51.4</td>\n      <td>58.3</td>\n      <td>43.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Filepaths\n\nNote, that our input file `'Kumpula-June-2016-w-metadata.txt'` is located **in the same folder** as the notebook we are running. Furthermore, the same folder is the working directory for our Python session (you can check this by running the `%pwd` magic command).\nFor these two reasons, we are able to pass only the filename to `.read_csv()` function and pandas is able to find the file and read it in. In fact, we are using a **relative filepath** when reading in the file.\n    \nThe **absolute filepath** to the input data file in the CSC cloud computing environment is `/home/jovyan/my-work/notebooks/L5/Kumpula-June-2016-w-metadata.txt`, and we could also use this as input when reading in the file. When working with absolute filepaths, it's good practice to pass the file paths as a [raw string](https://docs.python.org/3/reference/lexical_analysis.html#literals) using the prefix `r` in order to avoid problems with escape characters such as `\"\\n\"`.\n\n```python    \n# Define file path as a raw string:\nfp = r'/home/jovyan/my-work/notebooks/L5/Kumpula-June-2016-w-metadata.txt'\n\n# Read in the data from the file (starting at row 9):\ndata = pd.read_csv(fp, skiprows=8)\n``` ","metadata":{}},{"cell_type":"markdown","source":"## Basic calculations\n\nOne of the most common things to do in pandas is to create new columns based on calculations between different variables (columns).\n\nWe can create a new column `DIFF` in our DataFrame by specifying the name of the column and giving it some default value (in this case the decimal number `0.0`).","metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":"# Define a new column \"DIFF\"\ndata[\"DIFF\"] = 0.0\n\n# Check how the dataframe looks like:\ndata","metadata":{"tags":[],"collapsed":false,"jupyter":{"outputs_hidden":false},"deletable":true,"editable":true,"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"    YEARMODA  TEMP   MAX   MIN  DIFF\n0   20160601  65.5  73.6  54.7   0.0\n1   20160602  65.8  80.8  55.0   0.0\n2   20160603  68.4   NaN  55.6   0.0\n3   20160604  57.5  70.9  47.3   0.0\n4   20160605  51.4  58.3  43.2   0.0\n5   20160606  52.2  59.7  42.8   0.0\n6   20160607  56.9  65.1  45.9   0.0\n7   20160608  54.2   NaN  47.5   0.0\n8   20160609  49.4  54.1  45.7   0.0\n9   20160610  49.5  55.9  43.0   0.0\n10  20160611  54.0  62.1  41.7   0.0\n11  20160612  55.4  64.2  46.0   0.0\n12  20160613  58.3  68.2  47.3   0.0\n13  20160614  59.7  67.8  47.8   0.0\n14  20160615  63.4  70.3  49.3   0.0\n15  20160616  57.8  67.5  55.6   0.0\n16  20160617  60.4  70.7  55.9   0.0\n17  20160618  57.3   NaN  54.0   0.0\n18  20160619  56.3  59.2  54.1   0.0\n19  20160620  59.3  69.1  52.2   0.0\n20  20160621  62.6  71.4  50.4   0.0\n21  20160622  61.7  70.2  55.4   0.0\n22  20160623  60.9  67.1  54.9   0.0\n23  20160624  61.1  68.9  56.7   0.0\n24  20160625  65.7  75.4  57.9   0.0\n25  20160626  69.6  77.7  60.3   0.0\n26  20160627  60.7  70.0   NaN   0.0\n27  20160628  65.4  73.0  55.8   0.0\n28  20160629  65.8  73.2   NaN   0.0\n29  20160630  65.7  72.7  59.2   0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>YEARMODA</th>\n      <th>TEMP</th>\n      <th>MAX</th>\n      <th>MIN</th>\n      <th>DIFF</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20160601</td>\n      <td>65.5</td>\n      <td>73.6</td>\n      <td>54.7</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20160602</td>\n      <td>65.8</td>\n      <td>80.8</td>\n      <td>55.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20160603</td>\n      <td>68.4</td>\n      <td>NaN</td>\n      <td>55.6</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20160604</td>\n      <td>57.5</td>\n      <td>70.9</td>\n      <td>47.3</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20160605</td>\n      <td>51.4</td>\n      <td>58.3</td>\n      <td>43.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>20160606</td>\n      <td>52.2</td>\n      <td>59.7</td>\n      <td>42.8</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>20160607</td>\n      <td>56.9</td>\n      <td>65.1</td>\n      <td>45.9</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>20160608</td>\n      <td>54.2</td>\n      <td>NaN</td>\n      <td>47.5</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>20160609</td>\n      <td>49.4</td>\n      <td>54.1</td>\n      <td>45.7</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>20160610</td>\n      <td>49.5</td>\n      <td>55.9</td>\n      <td>43.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>20160611</td>\n      <td>54.0</td>\n      <td>62.1</td>\n      <td>41.7</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>20160612</td>\n      <td>55.4</td>\n      <td>64.2</td>\n      <td>46.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>20160613</td>\n      <td>58.3</td>\n      <td>68.2</td>\n      <td>47.3</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>20160614</td>\n      <td>59.7</td>\n      <td>67.8</td>\n      <td>47.8</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>20160615</td>\n      <td>63.4</td>\n      <td>70.3</td>\n      <td>49.3</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>20160616</td>\n      <td>57.8</td>\n      <td>67.5</td>\n      <td>55.6</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>20160617</td>\n      <td>60.4</td>\n      <td>70.7</td>\n      <td>55.9</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>20160618</td>\n      <td>57.3</td>\n      <td>NaN</td>\n      <td>54.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>20160619</td>\n      <td>56.3</td>\n      <td>59.2</td>\n      <td>54.1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>20160620</td>\n      <td>59.3</td>\n      <td>69.1</td>\n      <td>52.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20160621</td>\n      <td>62.6</td>\n      <td>71.4</td>\n      <td>50.4</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>20160622</td>\n      <td>61.7</td>\n      <td>70.2</td>\n      <td>55.4</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>20160623</td>\n      <td>60.9</td>\n      <td>67.1</td>\n      <td>54.9</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>20160624</td>\n      <td>61.1</td>\n      <td>68.9</td>\n      <td>56.7</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>20160625</td>\n      <td>65.7</td>\n      <td>75.4</td>\n      <td>57.9</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>20160626</td>\n      <td>69.6</td>\n      <td>77.7</td>\n      <td>60.3</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>20160627</td>\n      <td>60.7</td>\n      <td>70.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>20160628</td>\n      <td>65.4</td>\n      <td>73.0</td>\n      <td>55.8</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>20160629</td>\n      <td>65.8</td>\n      <td>73.2</td>\n      <td>NaN</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>20160630</td>\n      <td>65.7</td>\n      <td>72.7</td>\n      <td>59.2</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's check the datatype of our new column:","metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":"data[\"DIFF\"].dtypes","metadata":{"tags":[],"collapsed":false,"jupyter":{"outputs_hidden":false},"deletable":true,"editable":true,"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"dtype('float64')"},"metadata":{}}]},{"cell_type":"markdown","source":"OK, so we see that pandas created a new column and recognized automatically that the data type is float as we passed a 0.0 value to it.\n\nLet's update the column `DIFF` by calculating the difference between `MAX` and `MIN` columns to get an idea how much the temperatures have varied during the set of days:","metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":"# Calculate max min difference\n\n\n# Check the result\n","metadata":{"collapsed":false,"deletable":true,"editable":true,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The calculations were stored into the `DIFF` column as planned. \n\nYou can also create new columns on-the-fly at the same time when doing the calculation (the column does not have to exist before). Furthermore, it is possible to use any kind of math operation (e.g., subtraction, addition, multiplication, division, exponentiation, etc.) when creating new columns.\n\nWe can, for example, convert the Fahrenheit temperatures in the `TEMP` column to Celsius using the formula that we have already seen in this course many times. Let's do that and store it in a new column called `TEMP_CELSIUS`.","metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":"# Create a new column and convert temp fahrenheit to celsius:\n\n\n# Check output\n","metadata":{"collapsed":false,"deletable":true,"editable":true,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Check your understanding\n\nCalculate the temperatures in Kelvins using the Celsius values and store the result a new column called `TEMP_KELVIN` in our DataFrame.\n    \nAs a reminder, zero Kelvins is -273.15 degrees Celsius as we learned in [Lesson 4](https://geo-python-site.readthedocs.io/en/latest/notebooks/L4/functions.html#let-s-make-another-function).","metadata":{}},{"cell_type":"code","source":"# Type in your solution below\n","metadata":{"tags":["hide-cell"]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Selecting rows and columns\n\nWe often want to select only specific rows from a DataFrame for further analysis. There are multiple ways of selecting subsets of a pandas DataFrame. In this section we will go through the most useful approaches for selecting specific rows, columns and individual values.\n\n### Selecting several rows\n\nOne common way of selecting only specific rows from your DataFrame is done via *index slicing* to extract part of the DataFrame. Slicing in pandas can be done in a similar manner as with normal Python lists (i.e., you specify the index range you want to select inside the square brackets): `dataframe[start_index:stop_index]`.\n\nLet's select the first five rows and assign them to a variable called `selection`:","metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":"# Select first five rows of dataframe using row index values\n","metadata":{"collapsed":false,"deletable":true,"editable":true,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Note**: Here we have selected the first five rows (index 0-4) using the integer index.","metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":"### Selecting several rows and columns\n\nIt is also possible to control which columns are chosen when selecting a subset of rows. In this case we will use [pandas.DataFrame.loc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) which selects data based on axis labels (row labels and column labels). \n\nLet's select temperature values (column `TEMP`) from rows 0-5:","metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":"# Select temp column values on rows 0-5\n","metadata":{"collapsed":false,"deletable":true,"editable":true,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Note**: In this case, we get six rows of data (index 0-5)! We are now doing the selection based on axis labels instead of the integer index.","metadata":{}},{"cell_type":"markdown","source":"It is also possible to select multiple columns when using `loc`. Here, we select the `TEMP` and `TEMP_CELSIUS` columns from a set of rows by passing them inside a list (`.loc[start_index:stop_index, list_of_columns]`):","metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":"# Select columns temp and temp_celsius on rows 0-5\n","metadata":{"collapsed":false,"deletable":true,"editable":true,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Check your understanding\n\nFind the mean temperatures (in Celsius) for the last seven days of June. Do the selection using the row index values.","metadata":{}},{"cell_type":"code","source":"# Type in your solution below\n","metadata":{"tags":["hide-cell"]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Selecting a single row\n\nYou can also select an individual row from a specific position using the `.loc[]` indexing. Here we select all the data values using index 4 (the 5th row):","metadata":{}},{"cell_type":"code","source":"# Select one row using index\n","metadata":{"collapsed":false,"deletable":true,"editable":true,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"``.loc[]`` indexing returns the values from that position as a ``pd.Series`` where the indices are actually the column names of those variables. Hence, you can access the value of an individual column by referring to its index using the following format (both should work):\n","metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":"# Print one attribute from the selected row\n","metadata":{"collapsed":false,"deletable":true,"editable":true,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Selecting a single value based on row and column\n\nSometimes it is enough to access a single value in a DataFrame. In this case, we can use [DataFrame.at](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.at.html#pandas-dataframe-at) instead of `Data.Frame.loc`.\n\nLet's select the temperature (column `TEMP`) on the first row (index `0`) of our DataFrame.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Selections by integer position (*optional*)\n\n#### .iloc\n\n`.loc` and `.at` are based on the *axis labels*, the names of columns and rows. Axis labels can also be something other than the \"traditional\" index values (e.g., `0`, `1`, ...). For example, datetime is commonly used as the row index for rows listed according to the date and time of the data.\n\n`.iloc` is another indexing operator which is based on *integer value* indices. Using `.iloc`, it is possible to refer also to the columns based on their index value. For example,  `data.iloc[0,0]` would return `20160601` in our example DataFrame.\n    \nSee the pandas documentation for more information about [indexing and selecting data](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-and-selecting-data).\n\nFor example, we could select `TEMP` and the `TEMP_CELSIUS` columns from a set of rows based on their index.","metadata":{}},{"cell_type":"code","source":"data.iloc[0:5:, 0:2]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To access the value on the first row and second column (`TEMP`), the syntax for `iloc` would be:\n    ","metadata":{}},{"cell_type":"code","source":"data.iloc[0, 1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can also access individual rows using `iloc`. Let's check out the last row of data:","metadata":{}},{"cell_type":"code","source":"data.iloc[-1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Filtering and updating data\n\nOne really useful feature in pandas is the ability to easily filter and select rows based on a conditional statement.\nThe following example shows how to select rows when the Celsius temperature has been higher than 15 degrees and store them in the variable `warm_temps` (warm temperatures). pandas checks if the condition is `True` or `False` for each row, and returns those rows where the condition is `True`:","metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":"# Check the condition\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select rows with temp celsius higher than 15 degrees\n","metadata":{"collapsed":false,"deletable":true,"editable":true,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is also possible to combine multiple criteria at the same time. Here, we select temperatures above 15 degrees that were recorded on the second half of June in 2016 (i.e. `YEARMODA >= 20160615`).\nCombining multiple criteria can be done with the `&` operator (AND) or the `|` operator (OR). Notice, that it is often useful to separate the different clauses using parentheses `()`.","metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":"# Select rows with temp celsius higher than 15 degrees from late June 2016\n","metadata":{"collapsed":false,"deletable":true,"editable":true,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we have a subset of our DataFrame with only rows where the `TEMP_CELSIUS` is above 15 and the dates in `YEARMODA` column start from the 15th of June.\n\nNotice, that the index values (numbers on the left) are still showing the positions from the original DataFrame. It is possible to *reset* the index using the `reset_index()` function, which might be useful in some cases to be able to slice the data in a manner similar to that above. By default `reset_index()` would create a new column called `index` to keep track of the previous index, which might be useful in some cases. That is not hte case here, so we can omit that behavior by passing the parameter `drop=True`.","metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":"# Reset index\n","metadata":{"collapsed":false,"deletable":true,"editable":true,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see, now the index values go from 0 to 12 now.","metadata":{}},{"cell_type":"markdown","source":"#### Check your understanding\n\nFind the mean temperatures (in Celsius) for the last seven days of June again. This time you should select the rows based on a condition for the `YEARMODA` column!","metadata":{}},{"cell_type":"code","source":"# Type in your solution below\n","metadata":{"tags":["hide-cell"]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Deep copy\n\nIn this lesson, we have stored subsets of a DataFrame as a new variable. In some cases, we are still referring to the original data and any modifications made to the new variable might affect the original DataFrame.\n    \nIf you want to be extra careful to not modify the original DataFrame, then you should take a *deep copy* of the data before proceeding using the `.copy()` method. You can read more about indexing, selecting data and deep and shallow copies in the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html) and in [this excellent blog post](https://medium.com/dunder-data/selecting-subsets-of-data-in-pandas-part-4-c4216f84d388).","metadata":{}},{"cell_type":"markdown","source":"## Dealing with missing data\n\nAs you may have noticed by now, we have several missing values in the temperature minimum, maximum, and difference columns (`MIN`, `MAX`, and `DIFF`). These missing values are indicated as `NaN` (not a number). Having missing data in your datafile is a common situation and typically you want to deal with it somehow. Common procedures to deal with `NaN` values are to either remove them from the DataFrame or fill them with some other value. In pandas both of these options are easy to do.\n\nLet's first see how we can remove the NoData values (i.e., clean the data) using the [.dropna()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html) function. Inside the function you can pass a list of column(s) from which the `NaN` values should found using the `subset` parameter. The output will drop any row containing `NaN` values from the set of columns provided to the `subset` parameter.","metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":"# Drop NaN values based on the MIN column\n","metadata":{"collapsed":false,"deletable":true,"editable":true,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see by looking at the table above (and the change in index values), we now have a DataFrame without the NoData values.\n\n**Note**: Note that we replaced the original `warm_temps` variable with version where no data are removed. The `.dropna()` function, among other pandas functions can also be applied \"inplace\" which means that the function updates the DataFrame object and returns `None`:\n    \n```python\nwarm_temps.dropna(subset=['MIN'], inplace=True)\n```\n\nAnother option is to fill the NoData with some value using the `fillna()` function. Here we can fill the missing values in the with value -9999. Note that we are not giving the `subset` parameter this time.","metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":"# Fill NaN values\n","metadata":{"collapsed":false,"deletable":true,"editable":true,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As a result we now have a DataFrame where NoData values are filled with the value -9999.","metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":"**Warning**: In many cases filling the data with a specific value is dangerous because you end up modifying the actual data, which might affect the results of your analysis. For example, in the case above we would have dramatically changed the temperature difference columns because the -9999 values not an actual temperature difference! Hence, use caution when filling missing values. \n    \nYou might have to fill in no data values for the purposes of saving the data to file in a specific format. For example, some GIS software does not accept missing values. Always pay attention to potential no data values when reading in data files and doing further analysis!","metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":"## Data type conversions","metadata":{}},{"cell_type":"markdown","source":"There are occasions where you'll need to convert data stored within a Series to another data type, for example, from floating point to integer.","metadata":{"editable":true}},{"cell_type":"markdown","source":"Remember, that we already did data type conversions using the [built-in Python functions](https://docs.python.org/3/library/functions.html#built-in-functions) such as `int()` or `str()`.","metadata":{}},{"cell_type":"markdown","source":"For values in pandas DataFrames and Series, we can use the `astype()` method.","metadata":{}},{"cell_type":"markdown","source":"#### Truncating versus rounding up\n\n**Be careful with type conversions from floating point values to integers.** The conversion simply drops the stuff to the right of the decimal point, so all values are rounded down to the nearest whole number. For example, 99.99 will be truncated to 99 as an integer, when it should be rounded up to 100.\n\nChaining the round and type conversion functions solves this issue as the `.round(0).astype(int)` command first rounds the values with zero decimals and then converts those values into integers.","metadata":{"editable":true}},{"cell_type":"code","source":"print(\"Original values:\")\ndata[\"TEMP\"].head()","metadata":{"trusted":true,"tags":[]},"execution_count":7,"outputs":[{"name":"stdout","text":"Original values:\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"0    65.5\n1    65.8\n2    68.4\n3    57.5\n4    51.4\nName: TEMP, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Truncated integer values:\")\n","metadata":{"trusted":true,"tags":[]},"execution_count":8,"outputs":[{"name":"stdout","text":"Truncated integer values:\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Rounded integer values:\")\n","metadata":{"tags":[],"collapsed":false,"jupyter":{"outputs_hidden":false},"editable":true,"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Rounded integer values:\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Looks correct now.","metadata":{}},{"cell_type":"markdown","source":"## Unique values","metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":"Sometimes it is useful to extract the unique values that you have in your column.\nWe can do that by using the `unique()` method:","metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":"# Get unique celsius values\nunique = ","metadata":{"collapsed":false,"deletable":true,"editable":true,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As a result we get an array of unique values in that column.","metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":"**Note**: Sometimes if you have a long list of unique values, you don't necessarily see all the unique values directly as IPython/Jupyter may hide them with an ellipsis `...`. It is, however, possible to see all those values by printing them as a list.","metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":"# unique values as list\nlist(unique)","metadata":{"collapsed":false,"deletable":true,"editable":true,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"How many days with unique mean temperature did we have in June 2016? We can check that!\n","metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":"# Number of unique values\nunique_temps = len(unique)\nprint(f\"There were {unique_temps} days with unique mean temperatures in June 2016.\")","metadata":{"tags":[],"collapsed":false,"jupyter":{"outputs_hidden":false},"deletable":true,"editable":true,"trusted":true},"execution_count":10,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Number of unique values\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m unique_temps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43munique\u001b[49m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere were \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munique_temps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m days with unique mean temperatures in June 2016.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'unique' is not defined"],"ename":"NameError","evalue":"name 'unique' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"## Sorting data\n\nQuite often it is useful to be able to sort your data (descending/ascending) based on values in some column\nThis can be easily done with pandas using the `sort_values(by='YourColumnName')` function.\n\nLet's first sort the values on ascending order based on the `TEMP` column:","metadata":{}},{"cell_type":"code","source":"# Sort DataFrame by temperature, ascending\n","metadata":{"collapsed":false,"deletable":true,"editable":true,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Of course, it is also possible to sort them in descending order with ``ascending=False`` parameter:\n","metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":"# Sort DataFrame by temperature, descending\n","metadata":{"collapsed":false,"deletable":true,"editable":true,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Writing data to a file\n\nLastly, it is important to be able to write the data that you have analyzed to a file on your computer. This is really handy in pandas as it [supports many different data formats by default](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html).\n\nThe most typical output format by far is a CSV file. The function `to_csv()` can be used to easily save your data in the CSV format. Let's first save the data from our `data` DataFrame into a file called `Kumpula_temp_results_June_2016.csv`.","metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":"# define output filename\n\n\n# Save dataframe to csv\n","metadata":{"collapsed":false,"deletable":true,"editable":true,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we have the data from our DataFrame saved to a file:\n![Text file output1](img/pandas-save-file-1.png)\n\nAs you can see, the first value in the data file now contains the index value of the rows. There are also quite a lot of decimals present in the new columns\nthat we created. Let's deal with these and save the temperature values from the `warm_temps` DataFrame without the index and with only 1 decimal for the floating point numbers.","metadata":{"deletable":true,"editable":true}},{"cell_type":"code","source":"# define output filename\n\n\n# Save dataframe to csv\n","metadata":{"collapsed":false,"deletable":true,"editable":true,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Omitting the index can be done with the `index=False` parameter. Specifying how many decimals should be written can be done with the `float_format` parameter where the text `%.1f` instructs pandas to use 1 decimal in all columns when writing the data to a file (changing the value 1 to 2 would write 2 decimals, etc.)\n\n![Output after float fomatting](img/pandas-save-file-2.png)\n\nAs a result you have a \"cleaner\" output file without the index column, and with only 1 decimal for floating point numbers.","metadata":{"deletable":true,"editable":true}},{"cell_type":"markdown","source":"That's it for this week. We will dive deeper into data analysis with pandas in the Lesson 6.","metadata":{}}]}